{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "            data_path = 'dataset.csv',\n",
    "            cat_cols = ['Blood type', 'Gender', 'Doner Province', 'Camp held provinces'],\n",
    "            label_encoder_path = 'weights/donation-2023/label_encoder.pkl',\n",
    "            ):\n",
    "    \"\"\"Load data from csv file\"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    del data['Blood camp held date']\n",
    "    del data['Last donated date']\n",
    "    \n",
    "    columns = data.columns.values\n",
    "    data.columns = [col.strip() for col in columns]\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype(str).str.strip()\n",
    "    data = data.dropna(axis=0, how='any')\n",
    "    \n",
    "    # Load label encoder\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    if os.path.exists(label_encoder_path):\n",
    "        with open(label_encoder_path, 'rb') as f:\n",
    "            d = pickle.load(f)\n",
    "        for col in cat_cols:\n",
    "            data[col] = d[col].transform(data[col])\n",
    "    else:\n",
    "        for col in cat_cols:\n",
    "            data[col] = d[col].fit_transform(data[col])\n",
    "        with open(label_encoder_path, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "    \n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype(float)\n",
    "\n",
    "    Y = data['Label'].values\n",
    "    X = data.drop(['Label'], axis=1).values\n",
    "    return X, Y, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inputs, outputs, d \u001b[39m=\u001b[39m load_data()\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(inputs, outputs, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_path, cat_cols, label_encoder_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\n\u001b[0;32m      2\u001b[0m             data_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m             cat_cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mBlood type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDoner Province\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCamp held provinces\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m             label_encoder_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweights/donation-2023/label_encoder.pkl\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m             ):\n\u001b[0;32m      6\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load data from csv file\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_path)\n\u001b[0;32m      8\u001b[0m     \u001b[39mdel\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mBlood camp held date\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m     \u001b[39mdel\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mLast donated date\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ravin\\anaconda3\\envs\\predition2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\ravin\\anaconda3\\envs\\predition2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\ravin\\anaconda3\\envs\\predition2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\ravin\\anaconda3\\envs\\predition2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\ravin\\anaconda3\\envs\\predition2\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# inputs, outputs, d = load_data()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(inputs)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# with open('weights/donation-2023/scaler.pkl', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)\n",
    "# Load data\n",
    "inputs, outputs, d = load_data()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit StandardScaler to training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler using pickle\n",
    "import pickle\n",
    "\n",
    "# Make sure the directory 'weights/donation-2023' exists\n",
    "scaler_file_path = 'weights/donation-2023/scaler.pkl'\n",
    "with open(scaler_file_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "                            n_estimators=100, \n",
    "                            random_state=42\n",
    "                            )\n",
    "rfc.fit(X_train, outputs)\n",
    "\n",
    "# XGBoost Classifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "                    n_estimators=100,   \n",
    "                    random_state=42\n",
    "                    )\n",
    "xgb.fit(X_train, outputs)\n",
    "\n",
    "# Support Vector Machine\n",
    "\n",
    "svc = SVC(\n",
    "        kernel='linear',\n",
    "        random_state=42\n",
    "        )\n",
    "svc.fit(X_train, outputs)\n",
    "\n",
    "# KNN Classifier\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "                            n_neighbors=5,\n",
    "                            metric='minkowski',\n",
    "                            p=2\n",
    "                            )\n",
    "knn.fit(X_train, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "P_rfc = rfc.predict(X_test)\n",
    "P_xgb = xgb.predict(X_test)\n",
    "P_svc = svc.predict(X_test)\n",
    "P_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report - Random Forest Classifier\")\n",
    "print(classification_report(y_test, P_rfc))\n",
    "\n",
    "print(\"\\nClassification Report - XGBoost Classifier\")\n",
    "print(classification_report(y_test, P_xgb))\n",
    "\n",
    "print(\"\\nClassification Report - Support Vector Machine\")\n",
    "print(classification_report(y_test, P_svc))\n",
    "\n",
    "print(\"\\nClassification Report - KNN Classifier\")\n",
    "print(classification_report(y_test, P_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cm1 = confusion_matrix(y_test, P_rfc)\n",
    "cm2 = confusion_matrix(y_test, P_xgb)\n",
    "cm3 = confusion_matrix(y_test, P_svc)\n",
    "cm4 = confusion_matrix(y_test, P_knn)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Random Forest Classifier - CM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('XGBoost Classifier - CM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(cm3, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Support Vector Machine - CM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.heatmap(cm4, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('KNN Classifier - CM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'weights/donation-2023/xgb.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "sample_json = {\n",
    "                \"Age\": 60,\n",
    "                \"Blood type\": \"AB-\",\n",
    "                \"Gender\": \"F\",\n",
    "                \"Height (M)\": 1.76,\n",
    "                \"Weight\": 60,\n",
    "                \"BMI\": 19.36983471,\n",
    "                \"Blood camp held date\": \"10/14/2020\",\n",
    "                \"BMI Y/N\": 1,\n",
    "                \"Last donated date\": \"3/2/2018\",\n",
    "                \"Doner Province\": \"Uva\",\n",
    "                \"Camp held provinces\": \"Western\",\n",
    "                \"DonateBloodTill2023\": 1\n",
    "                }\n",
    "\n",
    "\n",
    "def inference(\n",
    "            sample_json,\n",
    "            cat_cols = ['Blood type', 'Gender', 'Doner Province', 'Camp held provinces'],\n",
    "            label_encoder_path = 'weights/donation-2023/label_encoder.pkl'\n",
    "            ):\n",
    "    sample = pd.DataFrame(sample_json, index=[0])\n",
    "    del sample['Blood camp held date']\n",
    "    del sample['Last donated date']\n",
    "\n",
    "    columns = sample.columns.values\n",
    "    sample.columns = [col.strip() for col in columns]\n",
    "    for col in sample.columns:\n",
    "        sample[col] = sample[col].astype(str).str.strip()\n",
    "\n",
    "    # Load label encoder\n",
    "    with open(label_encoder_path, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        sample[col] = d[col].transform(sample[col])\n",
    "        \n",
    "    for col in sample.columns:\n",
    "        sample[col] = sample[col].astype(float)\n",
    "\n",
    "    with open('weights/donation-2023/scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    sample = scaler.transform(sample)\n",
    "    pred = int(rfc.predict(sample).squeeze())\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "inference(sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ravin\\anaconda3\\envs\\predition2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ravin\\anaconda3\\envs\\predition2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
