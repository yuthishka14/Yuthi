{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re, os   \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns     \n",
    "import tensorflow as tf   \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "print('Tensorflow version : ', tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    for i in range(len(physical_devices)):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[i], True)\n",
    "    print(\"Consuming GPU for Training.\") \n",
    "    \n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_path = \"data/Blood Camp Reviews.xlsx\"\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "oov_token = '<OOV>'\n",
    "pad_token = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df_reviews = pd.read_excel(reviews_path, sheet_name='Reviews') \n",
    "    X = df_reviews.Reviews.values\n",
    "    Y = df_reviews.Sentiment.values\n",
    "    X, Y = shuffle(X, Y, random_state=1234)\n",
    "    return X, Y\n",
    "\n",
    "def lemmatization(lemmatizer,sentence):\n",
    "    lem = [lemmatizer.lemmatize(k) for k in sentence]\n",
    "    return [k for k in lem if k]\n",
    "\n",
    "def remove_stop_words(stopwords_list,sentence):\n",
    "    return [k for k in sentence if k not in stopwords_list]\n",
    "\n",
    "def preprocess_one(review):\n",
    "    review = review.lower()\n",
    "    remove_punc = tokenizer.tokenize(review) # Remove puntuations\n",
    "    remove_num = [re.sub('[0-9]', '', i) for i in remove_punc] # Remove Numbers\n",
    "    remove_num = [i for i in remove_num if len(i)>0] # Remove empty strings\n",
    "    lemmatized = lemmatization(lemmatizer,remove_num) # Word Lemmatization\n",
    "    remove_stop = remove_stop_words(stopwords_list,lemmatized) # remove stop words\n",
    "    updated_review = ' '.join(remove_stop)\n",
    "    return updated_review\n",
    "\n",
    "def preprocessed_data(reviews):\n",
    "    updated_reviews = []\n",
    "    if isinstance(reviews, np.ndarray) or isinstance(reviews, list):\n",
    "        updated_reviews = [preprocess_one(review) for review in reviews]\n",
    "    elif isinstance(reviews, np.str_)  or isinstance(reviews, str):\n",
    "        updated_reviews = [preprocess_one(reviews)]\n",
    "\n",
    "    return np.array(updated_reviews)\n",
    "\n",
    "def vis_class_imbalance(Y):\n",
    "    counts = pd.Series(Y).value_counts()\n",
    "    plt.rcParams['figure.figsize'] = (10, 10)\n",
    "    sns.barplot(\n",
    "            x=np.array(['Negative', 'Positive']),\n",
    "            y=counts.values\n",
    "               )  \n",
    "    plt.title('Class Imbalance of Review Dataset')\n",
    "    plt.xlabel('type')\n",
    "    plt.xlabel('Counts')\n",
    "    plt.savefig('visualization/imbalance_review.png')\n",
    "    plt.show()\n",
    "\n",
    "def create_wordcloud(processed_descriptions):\n",
    "    long_string = ','.join(list(processed_descriptions))\n",
    "    wordcloud = WordCloud(\n",
    "                        width=2000, \n",
    "                        height=1200, \n",
    "                        max_words=200, \n",
    "                        background_color='white',\n",
    "                        max_font_size=200, \n",
    "                        random_state=1234\n",
    "                        )\n",
    "    wordcloud.generate(long_string)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"WordCloud Distribution of Review Dataset\")\n",
    "    plt.savefig('visualization/review WordCloud Distribution.png')\n",
    "    plt.show()\n",
    "    \n",
    "def vis_length_variation(X_SEQ, Y):\n",
    "    X_SEQ_CG = np.array(X_SEQ)[Y==0]\n",
    "    X_SEQ_OR = np.array(X_SEQ)[Y==1]\n",
    "\n",
    "    X_len_CG = [len(i) for i in X_SEQ_CG]\n",
    "    X_len_OR = [len(i) for i in X_SEQ_OR]\n",
    "\n",
    "    X_len_CG = pd.Series(X_len_CG)\n",
    "    X_len_OR = pd.Series(X_len_OR)\n",
    "    \n",
    "    ax, fig = plt.subplots(1,2, figsize=(20,15))\n",
    "    X_len_CG.hist(ax=fig[0])\n",
    "    X_len_OR.hist(ax=fig[1])\n",
    "    fig[0].set_title('Negative')\n",
    "    fig[1].set_title('Positive')\n",
    "    fig[0].set_xlabel('Token Length')\n",
    "    fig[1].set_xlabel('Token Length')\n",
    "    fig[0].set_ylabel('Samples')\n",
    "    fig[1].set_ylabel('Samples')\n",
    "    plt.savefig('visualization/sequence_length_review.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(X_len_CG.describe())\n",
    "    print(X_len_OR.describe())\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "    X, Y = load_data()\n",
    "    vis_class_imbalance(Y)\n",
    "    \n",
    "    X = preprocessed_data(X)\n",
    "    create_wordcloud(X)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewSentimentAnalysis(object):\n",
    "    def __init__(self):\n",
    "        X, Y = retrieve_data()\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.max_length = 7\n",
    "        self.tokenizer_path = 'weights/review sentiment/tokenizer.pkl'\n",
    "        self.model_weights = 'weights/review sentiment/model.h5'\n",
    "\n",
    "    def save_load_tokenizer(self):\n",
    "        if not os.path.exists(self.tokenizer_path):\n",
    "            tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<oov>')\n",
    "            tokenizer.fit_on_texts(self.X)\n",
    "            \n",
    "            with open(self.tokenizer_path, 'wb') as fp:\n",
    "                pickle.dump(tokenizer, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "        else:\n",
    "            with open(self.tokenizer_path, 'rb') as fp:\n",
    "                tokenizer = pickle.load(fp)\n",
    "                \n",
    "        return tokenizer\n",
    "    \n",
    "    def handle_data(self):\n",
    "        tokenizer = self.save_load_tokenizer()\n",
    "        \n",
    "        X_seq = tokenizer.texts_to_sequences(self.X) # tokenize train data\n",
    "        vis_length_variation(X_seq, self.Y)\n",
    "\n",
    "        self.X_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                                                                    X_seq, \n",
    "                                                                    maxlen=self.max_length, \n",
    "                                                                    padding='pre', \n",
    "                                                                    truncating='pre'\n",
    "                                                                    )# Pad Train data\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = len(tokenizer.word_index) + 1\n",
    "        \n",
    "    def classifier(self, embedding_dim = 100): # Building the RNN model\n",
    "        inputs = tf.keras.layers.Input(shape=(self.max_length,), name='text_inputs')\n",
    "        x = tf.keras.layers.Embedding(\n",
    "                                        output_dim = embedding_dim, \n",
    "                                        input_dim = self.vocab_size, \n",
    "                                        input_length = self.max_length, \n",
    "                                        name = 'embedding'\n",
    "                                        )(inputs) # Embedding layer\n",
    "        \n",
    "        x = tf.keras.layers.Bidirectional(\n",
    "                                        tf.keras.layers.GRU(\n",
    "                                                            256,\n",
    "                                                            unroll=True,\n",
    "                                                            return_sequences = True\n",
    "                                                            )\n",
    "                                        )(x)\n",
    "        x = tf.keras.layers.Bidirectional(\n",
    "                                        tf.keras.layers.GRU(\n",
    "                                                            256,\n",
    "                                                            unroll=True,\n",
    "                                                            return_sequences = False\n",
    "                                                            )\n",
    "                                        )(x)\n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(64)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        model = tf.keras.models.Model(\n",
    "                                    inputs=inputs, \n",
    "                                    outputs=output\n",
    "                                    )\n",
    "        \n",
    "        model.summary()\n",
    "        self.model = model\n",
    "\n",
    "    def train(self):\n",
    "        self.classifier()\n",
    "        self.model.compile(\n",
    "                    loss='binary_crossentropy', \n",
    "                    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                    metrics=[\n",
    "                            tf.keras.metrics.BinaryAccuracy(),\n",
    "                            tf.keras.metrics.Precision(),\n",
    "                            tf.keras.metrics.Recall(),\n",
    "                            tf.keras.metrics.AUC()\n",
    "                            ]\n",
    "                        )\n",
    "        self.history = self.model.fit(\n",
    "                                self.X_pad,\n",
    "                                self.Y,\n",
    "                                batch_size = 32,\n",
    "                                epochs = 20,\n",
    "                                validation_split = 0.15\n",
    "                                )\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.model.save(self.model_weights)\n",
    "    \n",
    "    def loaded_model(self): # Load and compile pretrained model\n",
    "        self.model = tf.keras.models.load_model(self.model_weights)\n",
    "        self.model.compile(\n",
    "                        loss='binary_crossentropy', \n",
    "                        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                        metrics=[\n",
    "                                tf.keras.metrics.BinaryAccuracy(),\n",
    "                                tf.keras.metrics.Precision(),\n",
    "                                tf.keras.metrics.Recall(),\n",
    "                                tf.keras.metrics.AUC()\n",
    "                                ]\n",
    "                        )\n",
    "        self.model.summary()\n",
    "\n",
    "    def run(self):\n",
    "        self.handle_data()\n",
    "        if os.path.exists(self.model_weights):\n",
    "            self.loaded_model()\n",
    "        else:\n",
    "            self.train()\n",
    "            self.save_model()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bot = ReviewSentimentAnalysis()\n",
    "    bot.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bot.history.history\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history['binary_accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_binary_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Train and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history['precision_3'], label='Train Precision')\n",
    "plt.plot(history['val_precision_3'], label='Validation Precision')\n",
    "plt.title('Train and Validation Precision') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history['recall_3'], label='Train Recall')\n",
    "plt.plot(history['val_recall_3'], label='Validation Recall')\n",
    "plt.title('Train and Validation Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history['auc_3'], label='Train AUC')\n",
    "plt.plot(history['val_auc_3'], label='Validation AUC')\n",
    "plt.title('Train and Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('visualization/review_metrics.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(Y, P, title, save_path, cmap=None, normalize=True):\n",
    "    cf_matrix = confusion_matrix(Y, P)\n",
    "    labels = ['NEGATIVE', 'POSITIVE']\n",
    "    df_confusion = pd.DataFrame(cf_matrix, index = labels, columns=labels)\n",
    "    df_confusion['TOTAL'] = df_confusion.sum(axis=1)\n",
    "    df_confusion.loc['TOTAL']= df_confusion.sum()\n",
    "\n",
    "    # get percentages\n",
    "    df_percentages = df_confusion.div(df_confusion.TOTAL, axis=0)\n",
    "    df_percentages.TOTAL = 0\n",
    "\n",
    "    plt.figure(figsize=(24, 10))\n",
    "                            \n",
    "    sns.set(font_scale = 1.5)\n",
    "\n",
    "    # cmap using data for color, taking values from annot\n",
    "    ax = sns.heatmap(data=df_percentages, annot=df_confusion, cmap='Blues', fmt=\"d\",\n",
    "                    cbar_kws={'label': 'percentages'})  \n",
    "    \n",
    "    ax.set_title(title,size=22)\n",
    "    ax.set_xlabel('\\nPredicted Values',size=20)\n",
    "    ax.set_ylabel('Actual Values ', size=20)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = bot.Y\n",
    "X = bot.X_pad\n",
    "\n",
    "P = bot.model.predict(X)\n",
    "P = P.squeeze()\n",
    "P = np.round(P)\n",
    "\n",
    "plot_confusion_matrix(\n",
    "                      Y, P, \n",
    "                      'Confusion Matrix - Review Sentiment Analysis', \n",
    "                      'visualization/Confusion Matrix - Review Sentiment Analysis.png'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_inference(review):\n",
    "    review = preprocessed_data(review)\n",
    "    review = bot.tokenizer.texts_to_sequences(review)\n",
    "    review = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                                                            review, \n",
    "                                                            maxlen=bot.max_length, \n",
    "                                                            padding='pre', \n",
    "                                                            truncating='pre'\n",
    "                                                            )\n",
    "    pred = bot.model.predict(review).squeeze()\n",
    "    pred = np.round(pred)\n",
    "    return pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def derive_blood_camp_Scores():\n",
    "#     df_reviews = pd.read_excel(reviews_path, sheet_name='Reviews') \n",
    "#     df_reviews['Reviews'] = df_reviews['Reviews'].apply(preprocess_one)\n",
    "#     df_reviews['SentimentP'] = sample_inference(df_reviews['Reviews'].values)\n",
    "#     df_reviews = df_reviews[['Camp_Id', 'SentimentP']]\n",
    "#     df_reviews = df_reviews.groupby('Camp_Id').mean().reset_index()\n",
    "#     # round to 3 decimal places\n",
    "#     df_reviews['SentimentP'] = df_reviews['SentimentP'].round(3)\n",
    "#     df_reviews.to_csv('data/Blood Camp Reviewed.csv', index=False)\n",
    "\n",
    "# derive_blood_camp_Scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import re, os \n",
    "import pickle  \n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import tensorflow as tf   \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from math import sin, cos, sqrt, atan2, radians, asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_path = \"data/Blood Camp Reviews.xlsx\"\n",
    "reviewed_path = \"data/Blood Camp Reviewed.csv\"\n",
    "review_model_weights = 'weights/review sentiment/model.h5'\n",
    "review_tokenizer_path = 'weights/review sentiment/tokenizer.pkl'\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "oov_token = '<OOV>'\n",
    "pad_token = '<PAD>'\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "review_model = tf.keras.models.load_model(review_model_weights)\n",
    "review_model.compile(\n",
    "                    loss='binary_crossentropy',\n",
    "                    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    metrics=[\n",
    "                            tf.keras.metrics.BinaryAccuracy(),\n",
    "                            tf.keras.metrics.Precision(),\n",
    "                            tf.keras.metrics.Recall(),\n",
    "                            tf.keras.metrics.AUC()\n",
    "                            ]\n",
    "                    )\n",
    "\n",
    "with open(review_tokenizer_path, 'rb') as fp:\n",
    "    review_tokenizer = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(lemmatizer,sentence):\n",
    "    lem = [lemmatizer.lemmatize(k) for k in sentence]\n",
    "    return [k for k in lem if k]\n",
    "\n",
    "def remove_stop_words(stopwords_list,sentence):\n",
    "    return [k for k in sentence if k not in stopwords_list]\n",
    "\n",
    "def preprocess_one(review):\n",
    "    review = review.lower()\n",
    "    remove_punc = tokenizer.tokenize(review) # Remove puntuations\n",
    "    remove_num = [re.sub('[0-9]', '', i) for i in remove_punc] # Remove Numbers\n",
    "    remove_num = [i for i in remove_num if len(i)>0] # Remove empty strings\n",
    "    lemmatized = lemmatization(lemmatizer,remove_num) # Word Lemmatization\n",
    "    remove_stop = remove_stop_words(stopwords_list,lemmatized) # remove stop words\n",
    "    updated_review = ' '.join(remove_stop)\n",
    "    return updated_review\n",
    "\n",
    "def preprocessed_data(reviews):\n",
    "    updated_reviews = []\n",
    "    if isinstance(reviews, np.ndarray) or isinstance(reviews, list):\n",
    "        updated_reviews = [preprocess_one(review) for review in reviews]\n",
    "    elif isinstance(reviews, np.str_)  or isinstance(reviews, str):\n",
    "        updated_reviews = [preprocess_one(reviews)]\n",
    "\n",
    "    return np.array(updated_reviews)\n",
    "\n",
    "def inference_review(review):\n",
    "    review = preprocessed_data(review)\n",
    "    review = review_tokenizer.texts_to_sequences(review)\n",
    "    review = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                                                            review, \n",
    "                                                            maxlen=7, \n",
    "                                                            padding='pre', \n",
    "                                                            truncating='pre'\n",
    "                                                            )\n",
    "    pred = review_model.predict(review).squeeze()\n",
    "    pred = np.round(pred)\n",
    "    return pred.astype(int)\n",
    "\n",
    "def haversine(p1, p2):\n",
    "    lat1, lon1 = p1\n",
    "    lat2, lon2 = p2\n",
    "    \n",
    "    lat1 = float(lat1)\n",
    "    lon1 = float(lon1)\n",
    "    \n",
    "    lat2 = float(lat2)\n",
    "    lon2 = float(lon2)\n",
    "    \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    " \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    \n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 \n",
    "    distance_km = c * r\n",
    "    return distance_km\n",
    "\n",
    "def derive_blood_camps(\n",
    "                        user_location,\n",
    "                        max_distance = 10\n",
    "                        ):\n",
    "    df_reviews = pd.read_excel(reviews_path, sheet_name='Reviews') \n",
    "    df_locations = pd.read_excel(reviews_path, sheet_name='Locations')\n",
    "    df_reviews['Reviews'] = df_reviews['Reviews'].apply(preprocess_one)\n",
    "    df_reviews['SentimentP'] = inference_review(df_reviews['Reviews'].values)\n",
    "\n",
    "    df_reviews = df_reviews[['Camp_Id', 'SentimentP']]\n",
    "    df_reviews = df_reviews.groupby('Camp_Id').mean().reset_index()\n",
    "    df_reviews['SentimentP'] = df_reviews['SentimentP'].round(3)\n",
    "\n",
    "    df = pd.merge(df_reviews, df_locations, on='Camp_Id', how='left')\n",
    "    df[['Latitude', 'Longitude']] = df.Location.str.split(\",\", expand=True)\n",
    "    del df['Location']\n",
    "\n",
    "    df['Latitude'] = df['Latitude'].str.strip().astype(float)\n",
    "    df['Longitude'] = df['Longitude'].str.strip().astype(float)\n",
    "    df['Location'] = df[['Latitude', 'Longitude']].apply(tuple, axis=1)\n",
    "    del df['Latitude'], df['Longitude']\n",
    "    \n",
    "    df['distance'] = df['Location'].apply(\n",
    "                                            lambda x: haversine(\n",
    "                                                                user_location,                      \n",
    "                                                                x\n",
    "                                                                )\n",
    "                                        )\n",
    "    df = df[df['distance'] <= max_distance]\n",
    "    df = df.sort_values(by=['SentimentP'], ascending=False)\n",
    "    df = df[['Camp_Id', 'distance']]\n",
    "    df['distance'] = df['distance'].round(3).astype(str) + ' km'\n",
    "\n",
    "    response = df.to_dict('records')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Camp_Id': 'C5', 'distance': '0.71 km'},\n",
       " {'Camp_Id': 'C3', 'distance': '0.0 km'},\n",
       " {'Camp_Id': 'C2', 'distance': '1.511 km'},\n",
       " {'Camp_Id': 'C4', 'distance': '0.278 km'},\n",
       " {'Camp_Id': 'C1', 'distance': '0.431 km'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derive_blood_camps((6.920859540782977, 79.86867093270116))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4b521e29a846470c96e928a1c4aafac58a12234cdaa98f9ca60bc431873fee6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
